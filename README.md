# E-Commerce Real-Time Data Processing with Kafka & PySpark

This project focuses on the **integration, processing, and analysis** of real-time e-commerce sales data using Kafka and PySpark. Through it, we gain insights into purchasing patterns and ensure data quality for subsequent modeling stages.

## üåü Key Features:

1. **Real-Time Data Integration**: Leverage Kafka and PySpark to ingest and process e-commerce sales data in real time.
2. **Frequent Pattern Mining**: Explore common purchasing combinations using the FP-growth algorithm, revealing product affinities.
3. **Data Transformation & Quality**: Tackle challenges like null values and categorical data conversion to ready the data for analytical modeling.

## üöÄ Getting Started

### Prerequisites:

- Apache Kafka
- PySpark
- Python 3.x

### Installation:

1. Clone the repository:
```bash
git clone https://github.com/idanHur/Real-Time-Demand-Forecasting-in-E-commerce.git
```

2. Set up the environment:
Once the necessary files are downloaded, navigate to the project directory in your Linux terminal and execute the following commands to set up the environment:
```bash
cd e-commerce-data-processing
chmod +x setup_environment.sh
./setup_environment.sh
```
‚ö†Ô∏è Note: You might be prompted to enter your computer's password during the execution of the setup script.

3. Run the Project:
With the setup complete, a Jupyter notebook should open. Here, you can execute the project as per the instructions provided in the notebook.
